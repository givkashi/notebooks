{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore the main building block of Hezar which is the \"models\". In Hezar, models are the typical PyTorch modules with some extra features for loading, saving, exporting, etc. Lets dive into some of the most important ones!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like any other package, you can import any model from `hezar.models` that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/Applications/miniconda3/envs/main/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hezar.models import BertLM, BertLMConfig\n",
    "\n",
    "bert = BertLM(BertLMConfig())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also configure the architecture by changing the properties in a model's config like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertLMConfig(num_hidden_layers=8, num_attention_heads=8)\n",
    "bert = BertLM(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a model with registry name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hezar uses a global container for all of its modules called a `registry`. Registries are simple Python dictionaries that store a module class and its config class under a unique key. An example models' registry has the following format.\n",
    "\n",
    "```python\n",
    "{\n",
    "    'bert_lm': {\n",
    "        'model_class': hezar.models.language_modeling.bert.bert_lm.BertLM,\n",
    "        'config_class': hezar.models.language_modeling.bert.bert_lm_config.BertLMConfig\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, above is a sample models registry with one namespace called `bert_lm` that is a key to another dictionary that stores the model class and config class. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets use our `models_registry` to build a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hezar.registry import models_registry\n",
    "\n",
    "config = models_registry[\"bert_lm\"][\"config_class\"]()\n",
    "model = models_registry[\"bert_lm\"][\"model_class\"](config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be fair, this is not the cleanest way to build a model so let us introduce the `builders`! builders are some tiny functions to build a module using the registry name and pass custom config parameters as keyword arguments. Take a look at the below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hezar.builders import build_model\n",
    "\n",
    "bert = build_model(\"bert_lm\", num_hidden_layers=8, num_attention_heads=8)  # pass in config parameters as keyword arguments to the build function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But why?\n",
    "So you might ask, why would you store everything inside a registry when you can normally import anything you want and build instances?\n",
    "\n",
    "To answer this take a look at the below examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything\n",
    "from hezar import build_model, BertLM, BertLMConfig\n",
    "config = BertLMConfig(num_hidden_layers=8, num_attention_heads=8)\n",
    "bert = BertLM(config)\n",
    "\n",
    "# Use builder\n",
    "bert = build_model(\"bert_lm\", num_hidden_layers=8, num_attention_heads=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code examples are not way too different. In order to build a model with `build_model()` you have to know its registry name and build it with one line of code. But the downside is that your IDE/editor cannot give you proper suggestions as it does not know what type of a model it's returning! So it's actually up to you to pick the method you feel comfortable with, but the purpose of the registries is not just being able to build modules using their names! But in fact:\n",
    "1. Registries store every registered module in a single, global container so that accessing them is way simpler.\n",
    "2. Configuring a module type in a config file is better be of a string type. For example if you want to specify the type of the dataset, optimizer, etc. in a train config, you can just put its registry name and the rest is taken care of! As we go further you'll see more of these usecases.\n",
    "3. In Hezar, the base classes like `hezar.models.Model` or `hezar.configs.Config` or `hezar.preprocessors.Tokenizer` have a class method called `load()` that can load a fully functional module from the Hub. This method first downloads the config file and then builds the proper object using the `name` parameter which is, you guessed it!, the registry name of that module! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model from Hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model in Hezar, can be pushed to the Hub or downloaded from it. \n",
    "\n",
    "Loading a model from Hub is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hezar import Model\n",
    "\n",
    "bert = Model.load(\"hezarai/bert-base-fa\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your own model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add a model to Hezar or perhaps write a custom model with Hezar's Model functionalities follow the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from hezar import Model, ModelConfig, register_model\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerceptronConfig(ModelConfig):\n",
    "    name: str = \"perceptron\"\n",
    "    input_shape: int = 4\n",
    "    output_shape: int = 2\n",
    "\n",
    "@register_model(\"perceptron\", config_class=PerceptronConfig)\n",
    "class Perceptron(Model):\n",
    "    \"\"\"\n",
    "    A simple single layer network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.nn = nn.Linear(in_features=self.config.input_shape, out_features=self.config.output_shape)\n",
    "\n",
    "    def forward(self, inputs: list, **kwargs):\n",
    "        inputs = Tensor(inputs).reshape(1, -1)\n",
    "        x = self.nn(inputs)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceptronConfig(name='perceptron', config_type='model', input_shape=4, output_shape=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hezar.registry import models_registry\n",
    "models_registry['perceptron']['config_class']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6886, -0.6839]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron(PerceptronConfig())\n",
    "inputs = [1, 2, 3, 4]\n",
    "model.predict(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perceptron/model.pt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"perceptron\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Prepared repo `https://huggingface.co/hezarai/perceptron`. Starting push process...\n",
      "INFO: Uploaded `perceptron` config to `hezarai/perceptron/` as `model_config.yaml`\n",
      "model.pt: 100%|██████████| 1.05k/1.05k [00:02<00:00, 471B/s]  \n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "INFO: Uploaded model files to `hezarai/perceptron`\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"hezarai/perceptron\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
